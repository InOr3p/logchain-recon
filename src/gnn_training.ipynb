{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e8ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "class Config:\n",
    "    METADATA_DIR = \"metadata\"\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 0.001\n",
    "    EPOCHS = 20\n",
    "    HIDDEN_CHANNELS = 128\n",
    "    NUM_WORKERS = 4\n",
    "    MODEL_DIR = \"models\"\n",
    "\n",
    "print(f\"Using device: {Config.DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea1549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EFFICIENT DATASET LOADER ---\n",
    "class AlertGraphDataset(Dataset):\n",
    "    def __init__(self, metadata_path):\n",
    "        super().__init__()\n",
    "        self.metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def get(self, idx):\n",
    "        graph_info = self.metadata.iloc[idx]\n",
    "        filepath = graph_info['filepath']\n",
    "        label = graph_info['label_id']\n",
    "        \n",
    "        with np.load(filepath) as data:\n",
    "            node_feats = torch.from_numpy(data['node_feats']).float()\n",
    "            # Handle graphs with no edges\n",
    "            if 'sources' in data and data['sources'].size > 0:\n",
    "                edge_index = torch.from_numpy(\n",
    "                    np.vstack([data['sources'], data['destinations']])\n",
    "                ).long()\n",
    "            else:\n",
    "                edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        \n",
    "        return Data(x=node_feats, edge_index=edge_index, y=torch.tensor(label, dtype=torch.long))\n",
    "\n",
    "\n",
    "# Load label mapping to get class names\n",
    "label_map_path = os.path.join(Config.METADATA_DIR, 'label_map.json')\n",
    "with open(label_map_path, 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "id_to_label = {v: k for k, v in label_map.items()}\n",
    "num_classes = len(label_map)\n",
    "class_names = [id_to_label[i] for i in sorted(id_to_label.keys())]\n",
    "\n",
    "# Load all three datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_dataset = AlertGraphDataset(os.path.join(Config.METADATA_DIR, 'train.csv'))\n",
    "val_dataset = AlertGraphDataset(os.path.join(Config.METADATA_DIR, 'val.csv'))\n",
    "test_dataset = AlertGraphDataset(os.path.join(Config.METADATA_DIR, 'test.csv'))\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=Config.NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=Config.NUM_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=Config.NUM_WORKERS)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbfccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GNN MODEL FOR GRAPH CLASSIFICATION ---\n",
    "class GNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.classifier = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Node embedding phase\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        \n",
    "        # Graph pooling phase: aggregate node features into a single graph vector\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Final classification\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# --- TRAINING AND EVALUATION FUNCTIONS ---\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        batch = batch.to(Config.DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "            batch = batch.to(Config.DEVICE)\n",
    "            out = model(batch)\n",
    "            loss = criterion(out, batch.y)\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "            preds = out.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch.y.cpu().numpy())\n",
    "            \n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy, all_preds, all_labels\n",
    "\n",
    "\n",
    "# Calculate class weights for the loss function\n",
    "print(\"Calculating class weights...\")\n",
    "train_labels = pd.read_csv(os.path.join(Config.METADATA_DIR, 'train.csv'))['label_id'].values\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "weights = torch.tensor(class_weights, dtype=torch.float).to(Config.DEVICE)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "print(\"Weights calculated.\")\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = GNNClassifier(\n",
    "    in_channels=train_dataset.num_features,\n",
    "    hidden_channels=Config.HIDDEN_CHANNELS,\n",
    "    out_channels=num_classes\n",
    ").to(Config.DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "\n",
    "# --- Training Loop with Validation ---\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "best_val_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, Config.EPOCHS + 1):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion)\n",
    "    \n",
    "    print(f\"Epoch: {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save the model if validation loss improves\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_dir = os.path.join(Config.MODEL_DIR, \"graph_sage_classifier.pth\")\n",
    "        torch.save(model.state_dict(), save_dir)\n",
    "        print(f\"  -> Best model saved to {save_dir}\")\n",
    "\n",
    "print(\"\\n--- Training Finished ---\")\n",
    "\n",
    "# --- Final Evaluation on Test Set ---\n",
    "print(\"\\n--- Evaluating on Test Set ---\")\n",
    "# Load the best performing model\n",
    "model.load_state_dict(torch.load(save_dir))\n",
    "\n",
    "test_loss, test_acc, test_preds, test_labels = evaluate(model, test_loader, criterion)\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Display detailed classification report\n",
    "report = classification_report(test_labels, test_preds, target_names=class_names, zero_division=0)\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(report)\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix on Test Set')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
