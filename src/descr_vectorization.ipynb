{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94460974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import pytz\n",
    "import hdbscan\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "extract_dir = \"extracted_dataset\"\n",
    "parquet_processed_filename = \"processed_dataset_with_labels.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad41297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2600263 entries, 0 to 2600262\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   full_log           object \n",
      " 1   @timestamp         object \n",
      " 2   location           object \n",
      " 3   id                 float64\n",
      " 4   filename           object \n",
      " 5   agent_ip           object \n",
      " 6   data_srcip         object \n",
      " 7   rule_firedtimes    int64  \n",
      " 8   rule_level         int64  \n",
      " 9   rule_pci_dss       object \n",
      " 10  rule_tsc           object \n",
      " 11  rule_description   object \n",
      " 12  rule_groups        object \n",
      " 13  rule_id            object \n",
      " 14  rule_nist_800_53   object \n",
      " 15  rule_gdpr          object \n",
      " 16  unix_timestamp     float64\n",
      " 17  type_attack_label  object \n",
      " 18  attack_label       object \n",
      "dtypes: float64(2), int64(2), object(15)\n",
      "memory usage: 376.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(os.path.join(extract_dir, parquet_processed_filename))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29c3cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_log</th>\n",
       "      <th>@timestamp</th>\n",
       "      <th>location</th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>agent_ip</th>\n",
       "      <th>data_srcip</th>\n",
       "      <th>rule_firedtimes</th>\n",
       "      <th>rule_level</th>\n",
       "      <th>rule_pci_dss</th>\n",
       "      <th>rule_tsc</th>\n",
       "      <th>rule_description</th>\n",
       "      <th>rule_groups</th>\n",
       "      <th>rule_id</th>\n",
       "      <th>rule_nist_800_53</th>\n",
       "      <th>rule_gdpr</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>type_attack_label</th>\n",
       "      <th>attack_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan 15 02:32:32 mail freshclam[29266]: Sat Jan...</td>\n",
       "      <td>2022-01-15T02:32:32.000000Z</td>\n",
       "      <td>/var/log/syslog</td>\n",
       "      <td>1.686147e+09</td>\n",
       "      <td>fox</td>\n",
       "      <td>172.17.131.81</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[5.2]</td>\n",
       "      <td>[A1.2]</td>\n",
       "      <td>ClamAV database update</td>\n",
       "      <td>[clamd, freshclam, virus]</td>\n",
       "      <td>52507</td>\n",
       "      <td>[SI.3]</td>\n",
       "      <td>[IV_35.7.d]</td>\n",
       "      <td>1.642214e+09</td>\n",
       "      <td>false_positive</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan 15 02:32:32 taylorcruz-mail freshclam[2851...</td>\n",
       "      <td>2022-01-15T02:32:32.000000Z</td>\n",
       "      <td>/var/log/syslog</td>\n",
       "      <td>1.686147e+09</td>\n",
       "      <td>fox</td>\n",
       "      <td>192.168.128.170</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[5.2]</td>\n",
       "      <td>[A1.2]</td>\n",
       "      <td>ClamAV database update</td>\n",
       "      <td>[clamd, freshclam, virus]</td>\n",
       "      <td>52507</td>\n",
       "      <td>[SI.3]</td>\n",
       "      <td>[IV_35.7.d]</td>\n",
       "      <td>1.642214e+09</td>\n",
       "      <td>false_positive</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan 15 02:32:37 mail freshclam[29266]: Sat Jan...</td>\n",
       "      <td>2022-01-15T02:32:37.000000Z</td>\n",
       "      <td>/var/log/syslog</td>\n",
       "      <td>1.686147e+09</td>\n",
       "      <td>fox</td>\n",
       "      <td>172.17.131.81</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[5.2]</td>\n",
       "      <td>[A1.2]</td>\n",
       "      <td>ClamAV database update</td>\n",
       "      <td>[clamd, freshclam, virus]</td>\n",
       "      <td>52507</td>\n",
       "      <td>[SI.3]</td>\n",
       "      <td>[IV_35.7.d]</td>\n",
       "      <td>1.642214e+09</td>\n",
       "      <td>false_positive</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan 15 02:32:42 mail freshclam[29266]: Sat Jan...</td>\n",
       "      <td>2022-01-15T02:32:42.000000Z</td>\n",
       "      <td>/var/log/syslog</td>\n",
       "      <td>1.686147e+09</td>\n",
       "      <td>fox</td>\n",
       "      <td>172.17.131.81</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[5.2]</td>\n",
       "      <td>[A1.2]</td>\n",
       "      <td>ClamAV database update</td>\n",
       "      <td>[clamd, freshclam, virus]</td>\n",
       "      <td>52507</td>\n",
       "      <td>[SI.3]</td>\n",
       "      <td>[IV_35.7.d]</td>\n",
       "      <td>1.642214e+09</td>\n",
       "      <td>false_positive</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan 15 02:32:47 mail freshclam[29266]: Sat Jan...</td>\n",
       "      <td>2022-01-15T02:32:47.000000Z</td>\n",
       "      <td>/var/log/syslog</td>\n",
       "      <td>1.686147e+09</td>\n",
       "      <td>fox</td>\n",
       "      <td>172.17.131.81</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[5.2]</td>\n",
       "      <td>[A1.2]</td>\n",
       "      <td>ClamAV database update</td>\n",
       "      <td>[clamd, freshclam, virus]</td>\n",
       "      <td>52507</td>\n",
       "      <td>[SI.3]</td>\n",
       "      <td>[IV_35.7.d]</td>\n",
       "      <td>1.642214e+09</td>\n",
       "      <td>false_positive</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            full_log  \\\n",
       "0  Jan 15 02:32:32 mail freshclam[29266]: Sat Jan...   \n",
       "1  Jan 15 02:32:32 taylorcruz-mail freshclam[2851...   \n",
       "2  Jan 15 02:32:37 mail freshclam[29266]: Sat Jan...   \n",
       "3  Jan 15 02:32:42 mail freshclam[29266]: Sat Jan...   \n",
       "4  Jan 15 02:32:47 mail freshclam[29266]: Sat Jan...   \n",
       "\n",
       "                    @timestamp         location            id filename  \\\n",
       "0  2022-01-15T02:32:32.000000Z  /var/log/syslog  1.686147e+09      fox   \n",
       "1  2022-01-15T02:32:32.000000Z  /var/log/syslog  1.686147e+09      fox   \n",
       "2  2022-01-15T02:32:37.000000Z  /var/log/syslog  1.686147e+09      fox   \n",
       "3  2022-01-15T02:32:42.000000Z  /var/log/syslog  1.686147e+09      fox   \n",
       "4  2022-01-15T02:32:47.000000Z  /var/log/syslog  1.686147e+09      fox   \n",
       "\n",
       "          agent_ip data_srcip  rule_firedtimes  rule_level rule_pci_dss  \\\n",
       "0    172.17.131.81       None                1           3        [5.2]   \n",
       "1  192.168.128.170       None                2           3        [5.2]   \n",
       "2    172.17.131.81       None                3           3        [5.2]   \n",
       "3    172.17.131.81       None                4           3        [5.2]   \n",
       "4    172.17.131.81       None                5           3        [5.2]   \n",
       "\n",
       "  rule_tsc        rule_description                rule_groups rule_id  \\\n",
       "0   [A1.2]  ClamAV database update  [clamd, freshclam, virus]   52507   \n",
       "1   [A1.2]  ClamAV database update  [clamd, freshclam, virus]   52507   \n",
       "2   [A1.2]  ClamAV database update  [clamd, freshclam, virus]   52507   \n",
       "3   [A1.2]  ClamAV database update  [clamd, freshclam, virus]   52507   \n",
       "4   [A1.2]  ClamAV database update  [clamd, freshclam, virus]   52507   \n",
       "\n",
       "  rule_nist_800_53    rule_gdpr  unix_timestamp type_attack_label attack_label  \n",
       "0           [SI.3]  [IV_35.7.d]    1.642214e+09    false_positive       benign  \n",
       "1           [SI.3]  [IV_35.7.d]    1.642214e+09    false_positive       benign  \n",
       "2           [SI.3]  [IV_35.7.d]    1.642214e+09    false_positive       benign  \n",
       "3           [SI.3]  [IV_35.7.d]    1.642214e+09    false_positive       benign  \n",
       "4           [SI.3]  [IV_35.7.d]    1.642214e+09    false_positive       benign  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d617cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2600263 entries, 0 to 2600262\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   full_log           object \n",
      " 1   @timestamp         object \n",
      " 2   location           object \n",
      " 3   id                 float64\n",
      " 4   filename           object \n",
      " 5   agent_ip           object \n",
      " 6   data_srcip         object \n",
      " 7   rule_firedtimes    int64  \n",
      " 8   rule_level         int64  \n",
      " 9   rule_pci_dss       object \n",
      " 10  rule_tsc           object \n",
      " 11  rule_description   object \n",
      " 12  rule_groups        object \n",
      " 13  rule_id            object \n",
      " 14  rule_nist_800_53   object \n",
      " 15  rule_gdpr          object \n",
      " 16  unix_timestamp     float64\n",
      " 17  type_attack_label  object \n",
      " 18  attack_label       object \n",
      "dtypes: float64(2), int64(2), object(15)\n",
      "memory usage: 376.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17bab527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type_attack_label\n",
       "dirb                    1671940\n",
       "false_positive           882739\n",
       "wpscan                    28021\n",
       "dnsteal                    8603\n",
       "cracking                   5271\n",
       "service_scans              1768\n",
       "network_scans              1570\n",
       "privilege_escalation        158\n",
       "webshell                    109\n",
       "reverse_shell                80\n",
       "service_stop                  4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type_attack_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbf0a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading sentence transformer model...\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained Sentence Transformer model.\n",
    "# This model is excellent for semantic similarity tasks.\n",
    "print(\"\\nLoading sentence transformer model...\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1de52a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_df = df.sort_values(by='@timestamp').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2841e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame before vectorization ---\n",
      "                          @timestamp         agent_ip  \\\n",
      "0        2022-01-14T00:00:09.728242Z  192.168.104.218   \n",
      "1        2022-01-14T00:00:09.728242Z  192.168.104.218   \n",
      "2        2022-01-14T00:00:09.729820Z       10.229.0.4   \n",
      "3        2022-01-14T00:00:09.729820Z       10.229.0.4   \n",
      "4        2022-01-14T00:00:23.976670Z       10.229.0.4   \n",
      "...                              ...              ...   \n",
      "2600258  2022-02-08T23:47:19.000000Z     10.237.2.255   \n",
      "2600259  2022-02-08T23:47:22.000000Z   10.182.193.181   \n",
      "2600260  2022-02-08T23:47:22.000000Z   10.182.193.181   \n",
      "2600261  2022-02-08T23:47:24.000000Z     10.237.2.255   \n",
      "2600262  2022-02-08T23:47:24.000000Z     10.237.2.255   \n",
      "\n",
      "                                          rule_description  \n",
      "0        Suricata: Alert - ET INFO Observed DNS Query t...  \n",
      "1                  First time this IDS alert is generated.  \n",
      "2        Suricata: Alert - ET INFO Observed DNS Query t...  \n",
      "3                  First time this IDS alert is generated.  \n",
      "4        Suricata: Alert - ET POLICY GNU/Linux APT User...  \n",
      "...                                                    ...  \n",
      "2600258                             ClamAV database update  \n",
      "2600259                             ClamAV database update  \n",
      "2600260                             ClamAV database update  \n",
      "2600261                             ClamAV database update  \n",
      "2600262                             ClamAV database update  \n",
      "\n",
      "[2600263 rows x 3 columns]\n",
      "\n",
      "Loading sentence transformer model...\n",
      "Model loaded.\n",
      "\n",
      "Encoding descriptions into vectors...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e6ad250efc415b9bc140365765d1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Vectorization Step ---\n",
    "\n",
    "# Get the list of descriptions to encode.\n",
    "descriptions = logs_df['rule_description'].tolist()\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Encode the descriptions into vectors.\n",
    "# The model.encode() method processes the list of strings and returns a list of numpy arrays (vectors).\n",
    "print(\"\\nEncoding descriptions into vectors...\")\n",
    "description_vectors = embedding_model.encode(\n",
    "    descriptions, \n",
    "    batch_size=batch_size,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    show_progress_bar=True)\n",
    "\n",
    "description_vectors = normalize(description_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c418da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving DataFrame to Parquet...\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame (without the vector column) to Parquet.\n",
    "# This is fast and efficient for tabular data.\n",
    "print(\"Saving DataFrame to Parquet...\")\n",
    "logs_df.to_parquet(os.path.join(extract_dir, \"sorted_ds_with_labels.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vectors using NumPy's native, efficient binary format.\n",
    "# This is the key step to avoid the memory crash.\n",
    "print(\"Saving vectors to .npy file...\")\n",
    "np.save(os.path.join(extract_dir, \"vectorized_descr.npy\"), description_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7753a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data you saved previously\n",
    "logs_df = pd.read_parquet(os.path.join(extract_dir, 'sorted_ds_with_labels.parquet'))\n",
    "\n",
    "description_vectors = np.load(os.path.join(extract_dir, 'vectorized_descr.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f19e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Add the vectorized data to your DataFrame ---\n",
    "# (Assuming 'logs_df' is your DataFrame and 'description_vectors' is the numpy array from the last step)\n",
    "logs_df['description_vector'] = list(description_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff3c80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.vstack(logs_df['description_vector'].values)\n",
    "embeddings = normalize(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d488fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text at index 15: 'IDS event.'\n",
      "Cosine similarity between precomputed and newly generated vector: 1.0000001192092896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_vectorization(embeddings, index_to_check):\n",
    "    text_from_df = logs_df['rule_description'].iloc[index_to_check]\n",
    "    print(f\"Original text at index {index_to_check}: '{text_from_df}'\")\n",
    "\n",
    "    # Get the pre-computed vector from your saved NumPy array\n",
    "    precomputed_vector = embeddings[index_to_check]\n",
    "\n",
    "    # Generate a new vector from ONLY that specific text\n",
    "    newly_generated_vector = embedding_model.encode([text_from_df])[0]\n",
    "\n",
    "    # precomputed_vector = normalize(precomputed_vector.reshape(1, -1))[0]\n",
    "    newly_generated_vector = normalize(newly_generated_vector.reshape(1, -1))[0]\n",
    "\n",
    "    sim = np.dot(precomputed_vector, newly_generated_vector)\n",
    "    print(f\"Cosine similarity between precomputed and newly generated vector: {sim}\")\n",
    "    if sim >= 0.8:\n",
    "        return True\n",
    "    else: return False\n",
    "\n",
    "check_vectorization(embeddings, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f45c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text at index 10: 'Suricata: Alert - ET POLICY GNU/Linux APT User-Agent Outbound likely related to package management'\n",
      "\n",
      "Verification successful: True\n",
      "\n",
      "Max difference between any two elements: 7.07896106177941e-08\n",
      "Cosine Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "# --- Check if vectorized description at index X corresponds to X-th log description ---\n",
    "\n",
    "def check_vectorized_descr(index_to_check):\n",
    "    # Get the original text description from the DataFrame at that index\n",
    "    text_from_df = logs_df['rule_description'].iloc[index_to_check]\n",
    "    print(f\"Original text at index {index_to_check}: '{text_from_df}'\")\n",
    "\n",
    "    # Get the pre-computed vector from your saved NumPy array\n",
    "    precomputed_vector = logs_df['description_vector'].iloc[index_to_check]\n",
    "\n",
    "    # Generate a new vector from ONLY that specific text\n",
    "    newly_generated_vector = embedding_model.encode([text_from_df])[0]\n",
    "\n",
    "    # Compare the two vectors\n",
    "    # Use np.allclose() to account for tiny floating-point inaccuracies\n",
    "    are_vectors_the_same = np.allclose(precomputed_vector, newly_generated_vector, atol=1e-6)\n",
    "\n",
    "    print(f\"\\nVerification successful: {are_vectors_the_same}\")\n",
    "\n",
    "    # Print the actual difference between the vectors\n",
    "    vector_difference = precomputed_vector - newly_generated_vector\n",
    "    print(f\"\\nMax difference between any two elements: {np.max(np.abs(vector_difference))}\")\n",
    "\n",
    "    # You can also check their similarity score, which should be ~1.0\n",
    "    similarity = cos_sim(precomputed_vector, newly_generated_vector)\n",
    "    print(f\"Cosine Similarity: {similarity.item()}\")\n",
    "\n",
    "check_vectorized_descr(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
